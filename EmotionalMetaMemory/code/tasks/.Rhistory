file$NA_Cat <- 0
file$NA_Cat_Pre <- 0
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))*2
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))*2
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))*2
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))*2
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Get ID Coloumn to start at 1
file$X <- file$X+1
#Exclude NAs and the following Datapoint - as both NA values and the ones following were corrupted due to the Python Script
Extra_exclusion <- which(is.na(file$Confidence))+1
Extra_exclusion <- as.list((Extra_exclusion))
Extra_exclusion <- as.numeric(Extra_exclusion)
file <-subset(file, !(X %in% Extra_exclusion))
file <- na.omit(file)
#Exclude all trials with reactiontimes faster than 100 milliseconds aswell as negative trials
file <- filter(file, Confidence_RT >= 0.100)
file <- filter(file, RT >= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
View(temp_file1)
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
View(temp_file1)
View(temp_file2)
View(temp_file3)
View(temp_file4)
View(file)
View(temp_file1)
View(file)
#Setting Working Directory
setwd("/Users/sebastianscottengen/Google Drev/Hogwarts/5/Bachelor stuff/EmotionalMetaMemory/data/TaskData/SUBJ Data")
#Make a list of names in Working Directory
filenames = list.files(pattern = "*.txt")
#Show List
filenames
#Make Empty Dataframe
data = data.frame()
for (n_subjects in filenames){ #loop over list of files
#import the current file
file = read.delim(n_subjects, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- n_subjects
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
#Make Variable for number of NAs per SUBJ (We Multiply by 2 as we'll remove the datapoints following an NA aswell, as they were corrupted due to the Python Script)
file$NA_Sum <- sum(is.na(file))*2
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#Making Variables for how many NAs there is p category (We Multiply by 2 as we'll remove the datapoints following an NA aswell, as they were corrupted due to the Python Script) + Percentage per category
file$NA_Cat <- 0
file$NA_Cat_Pre <- 0
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))*2
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))*2
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))*2
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Get ID Coloumn to start at 1
file$X <- file$X+1
#Exclude NAs and the following Datapoint - as both NA values and the ones following were corrupted due to the Python Script
Extra_exclusion <- which(is.na(file$Confidence))+1
Extra_exclusion <- as.list((Extra_exclusion))
Extra_exclusion <- as.numeric(Extra_exclusion)
file <-subset(file, !(X %in% Extra_exclusion))
file <- na.omit(file)
#Exclude all trials with reactiontimes faster than 100 milliseconds aswell as negative trials
file <- filter(file, Confidence_RT >= 0.100)
file <- filter(file, RT >= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
#Checking for all 35 participants
unique(data$SUBJ)
#Checking for Participants with conditions with fewer than 50 trials
subset <- data[which(data[,21]>=0.66),]
View(subset)
#Plotting to get an idea of what to exclude
ggplot(data, aes(x = Cond, y = NA_Cat)) + geom_bar(stat = "summary", fun.y = mean) + facet_wrap(~SUBJ)
View(data)
View(data)
#Read the CSV
setwd("/Users/sebastianscottengen/Google Drev/Hogwarts/5/Bachelor stuff/EmotionalMetaMemory/code/tasks")
Meta_Summary_Demo <- read.csv("FinalWithOutHeart.csv")
View(Meta_Summary_Demo)
View(Meta_Summary_Demo)
#Participants with mean d' less than or equal to 0 will be excluded because this indicates that they are unable to do the task.
#Participants with mean meta-d' less than or equal to 0 will be excluded because m-ratio is uninterpretable in these cases.
hist(Meta_Summary_Demo$meta_d)
hist(Meta_Summary_Demo$d)
#Participants with mean d' less than or equal to 0 will be excluded because this indicates that they are unable to do the task.
#Participants with mean meta-d' less than or equal to 0 will be excluded because m-ratio is uninterpretable in these cases.
min(Meta_Summary_Demo$meta_d)
min(Meta_Summary_Demo$d)
#Loading Libraries
library(tidyverse) ; library(plyr) ; library(doBy) ; library(ggplot2) ; library(Hmisc)
#Setting Working Directory
knitr::opts_knit$set(root.dir = setwd('/Users/sebastianscottengen/Google Drev/Hogwarts/5/Bachelor stuff/EmotionalMetaMemory/data/Demographics'))
#Check Working Directory
getwd()
#Read Data
demographic_data <- read.csv("Demographics.csv", sep=";")
#Remove participant who didn't show up
demographic_data <- filter(demographic_data , Participant !="3")
#Calculating Median and Standard Deviation - Descriptors for Final Paper
median(demographic_data$Age)
sd(demographic_data$Age)
#Make Important Columns Numeric
demographic_data$Handedness_R_1 <- as.numeric(demographic_data$Handedness_R_1)
demographic_data$Gender_M_1 <- as.numeric(demographic_data$Gender_M_1)
View(demographic_data)
#Setting Working Directory
setwd("/Users/sebastianscottengen/Google Drev/Hogwarts/5/Bachelor stuff/EmotionalMetaMemory/data/TaskData/SUBJ Data")
#Make a list of names in Working Directory
filenames = list.files(pattern = "*.txt")
#Show List
filenames
#Make Empty Dataframe
data = data.frame()
#It Includes 35 Participants
for (n_subjects in filenames){ #loop over list of files
#import the current file
file = read.delim(n_subjects, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- n_subjects
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
#Make Variable for number of NAs per SUBJ (We Multiply by 2 as we'll remove the datapoints following an NA aswell, as they were corrupted due to the Python Script)
file$NA_Sum <- sum(is.na(file))*2
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#Making Variables for how many NAs there is p category (We Multiply by 2 as we'll remove the datapoints following an NA aswell, as they were corrupted due to the Python Script) + Percentage per category
file$NA_Cat <- 0
file$NA_Cat_Pre <- 0
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))*2
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))*2
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))*2
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Get ID Coloumn to start at 1
file$X <- file$X+1
#Exclude NAs and the following Datapoint - as both NA values and the ones following were corrupted due to the Python Script
Extra_exclusion <- which(is.na(file$Confidence))+1
Extra_exclusion <- as.list((Extra_exclusion))
Extra_exclusion <- as.numeric(Extra_exclusion)
file <-subset(file, !(X %in% Extra_exclusion))
file <- na.omit(file)
#Exclude all trials with reactiontimes faster than 100 milliseconds aswell as negative trials
file <- filter(file, Confidence_RT >= 0.100)
file <- filter(file, RT >= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
#Checking for all 35 participants
unique(data$SUBJ)
#Plotting to get an idea of what to exclude
Plot_1 <- ggplot(data, aes(x = Cond, y = NA_Cat)) + geom_bar(stat = "summary", fun.y = mean) + facet_wrap(~SUBJ)
Plot_1
#Participants with missing data (i.e. data loss due to technical failures) or insufficient data (fewer than 50 trials in total per condition) will be excluded.
#Checking for Participants with conditions with fewer than 50 trials
# Here we subset the dataframe looking for which participants have conditions with more than 66% of their data missing (So below 50 good trials in a condition)
subset <- data[which(data[,21]>=0.66),]
unique(subset$SUBJ)
#The Low Arousal and Low Valence group (A-V-) for "Subject_11113.txt", "Subject_11128.txt", "Subject_11131.txt", "Subject_47542.txt" has below 50 "good" trials and must therefore be excluded - This Stems with Plot_1
data <- filter(data,SUBJ!="Subject_47542.txt" & SUBJ!="Subject_11113.txt" & SUBJ!="Subject_11131.txt" & SUBJ!="Subject_11128.txt")
#Checking that we now have only 31 Participants
unique(data$SUBJ)
#Extra summaries for each participant and each condition for Accuracy, Confidence ReactionTime, ReactionTime and Confidence Scores
data$Accuracy <- as.numeric(data$Accuracy)
Sum_ACC <- doBy::summaryBy( Accuracy ~ SUBJ|Cond, data = data, FUN = list(mean, median, sd))
Sum_CRT <- doBy::summaryBy( Confidence_RT ~ SUBJ|Cond, data = data, FUN = list(mean, median, sd))
Sum_RT <- doBy::summaryBy( RT ~ SUBJ|Cond, data = data, FUN = list(mean, median, sd))
Sum_C <- doBy::summaryBy( Confidence ~ SUBJ|Cond, data = data, FUN = list(mean, median, sd))
#Add % accuracy (total correct trials for that condition/total trials for that condition) & Number of rejected trials per condition
Sum_rej_trials <- data.frame()
#Make list of SUBJs
SUBJ_list <- as.list(unique(data$SUBJ))
Condition_list <- as.list(unique(data$Cond))
#Go into Subjects
for (n_subjects in SUBJ_list){
#Go into Conditions
for(n_con in Condition_list){
temp1 <- filter(data, SUBJ == n_subjects & Cond == n_con)
p <- nrow(temp1)
l <- nrow(temp1)/150
S <- count(temp1$Accuracy == 1)
S <- S[2,2]/p
pls <- cbind(p,l,S)
Sum_rej_trials <- rbind(Sum_rej_trials,pls)
}}
names(Sum_rej_trials) <- c("Total_Accepted_Trials","Reject_Ratio_from_150", "Accuracy_in_percent")
#Bind all Summary data together into a final summary of ( Accuracy, Confidence ReactionTime, ReactionTime, Confidence Scores, % accuracy and Number of rejected trials)
Summary_data <- cbind(Sum_C,Sum_CRT,Sum_RT,Sum_ACC,Sum_rej_trials)
#Remove Duplicate Subject Coloumns
Summary_data <- subset(Summary_data, select=which(!duplicated(colnames(Summary_data))))
#Confidence
#Plot per Cond
ggplot(Summary_data, aes(x=Cond, y=Confidence.mean))+ geom_point(position = position_jitter(width = .15), size = .25) + geom_boxplot(alpha = 0.3, width = .1, colour = "BLACK")+ geom_violin(position = position_nudge(x = .5, y = 0),adjust =0.5, trim = TRUE)
#Accuracy
#Plot per Cond
ggplot(Summary_data, aes(x=Cond, y=Accuracy.mean))+ geom_point(position = position_jitter(width = .15), size = .25) + geom_boxplot(alpha = 0.3, width = .1, colour = "BLACK")+ geom_violin(position = position_nudge(x = .5, y = 0),adjust =0.5, trim = TRUE)
#RT
#Plot per Cond
ggplot(Summary_data, aes(x=Cond, y=RT.mean))+ geom_point(position = position_jitter(width = .15), size = .25) + geom_boxplot(alpha = 0.3, width = .1, colour = "BLACK")+ geom_violin(position = position_nudge(x = .5, y = 0),adjust =0.5, trim = TRUE)
#Confidence_RT
#Plot per Cond
ggplot(Summary_data, aes(x=Cond, y=Confidence_RT.mean))+ geom_point(position = position_jitter(width = .15), size = .25) + geom_boxplot(alpha = 0.3, width = .1, colour = "BLACK")+ geom_violin(position = position_nudge(x = .5, y = 0),adjust =0.5, trim = TRUE)
#Making plots of All data
ggplot(data, aes(x=Accuracy, y=Confidence, col=SUBJ))+
geom_smooth(method = "lm", se =F) + facet_wrap(~Cond)+
stat_summary(fun.y=mean, geom="line")
#To install rJags (https://gist.github.com/casallas/8411082)
## Load Libraries
library(tidyverse)
library(magrittr)
library(reshape2)
library(rjags)
library(coda)
library(lattice)
library(broom)
library(ggpubr)
library(ggmcmc)
#The Function
##It converts trial by trial experimental information for N trials into response counts.
"""
trials2counts <- function(stimID, response, rating,nRatings, padAmount = 0,padCells=0)
INPUTS
stimID - Input for expected Keypress in List Format
1xN vector.
stimID(i) = 0 --> stimulus on i'th trial was S1.
stimID(i) = 1 --> stimulus on i'th trial was S2.
response - Input for Actual Keypress in List Format
1xN vector.
response(i) = 0 --> response on i'th trial was 'S1'.
response(i) = 1 --> response on i'th trial was 'S2'.
rating - Input for Confidence Rating in List Format
1xN vector.
rating(i) = X --> rating on i'th trial was X.
X must be in the range 1 <= X <= nRatings.
nRatings - Total # of available subjective ratings available for the subject.
e.g. if subject can rate confidence on a scale of 1-4, then nRatings = 4
cellpad:
if set to 1, each response count in the output has the value of
1/(2*nRatings) added to it. This is desirable if trial counts of
0 interfere with model fitting.
if set to 0, trial counts are not manipulated and 0s may be present.
Default value is 0.
OUTPUTS
nR_S1, nR_S2
these are vectors containing the total number of responses in
each response category, conditional on presentation of S1 and S2.
e.g. if nR_S1 = [100 50 20 10 5 1],
then when stimulus S1 was
presented, the subject had the following response counts:
responded S1, rating=3 : 100 times
responded S1, rating=2 : 50 times
responded S1, rating=1 : 20 times
responded S2, rating=1 : 10 times
responded S2, rating=2 : 5 times
responded S2, rating=3 : 1 time
"""
trials2counts <- function(stimID, response, rating,nRatings, padAmount = 0,padCells=0){
nR_S1 <- list()
nR_S2 <- list()
if (padAmount == 0){
padAmount = 1/(2*nRatings)}
# S1 responses
for (r in nRatings:1){
cs1 <- 0
cs2 <- 0
for (i in 1:length(stimID)){
s = stimID[i]
x = response[i]
y = rating[i]
if ((s==0) & (x==0) & (y==r)){
(cs1 <- cs1+1)}
if ((s==1) & (x==0) & (y==r)){
(cs2 <- cs2+1)}
}
nR_S1 <- append(nR_S1,cs1)
nR_S2 <- append(nR_S2,cs2)
}
# S2 responses
for (r in 1:nRatings){
cs1 <- 0
cs2 <- 0
for (i in 1:length(stimID)){
s = stimID[i]
x = response[i]
y = rating[i]
if ((s==0) & (x==1) & (y==r)){
(cs1 <- cs1+1)}
if ((s==1) & (x==1) & (y==r)){
(cs2 <- cs2+1)}
}
nR_S1 <- append(nR_S1,cs1)
nR_S2 <- append(nR_S2,cs2)
}
# pad response counts to avoid zeros
nR_S1 <- as.numeric(nR_S1)
nR_S2 <- as.numeric(nR_S2)
if (padCells == 1){
nR_S1 <- lapply(nR_S1,FUN= function(x) x+padAmount)
nR_S2 <- lapply(nR_S2,FUN= function(x) x+padAmount)}
# Combine into lists
newlist <- list(nR_S1,nR_S2)
}
# Estimate metacognitive sensibility (meta d') for individual subject
#Working Directory Check
getwd()
setwd("/Users/sebastianscottengen/Google Drev/Hogwarts/5/Bachelor stuff/EmotionalMetaMemory/code/tasks")
metad_indiv <- function (nR_S1, nR_S2) {
Tol <- 1e-05
nratings <- length(nR_S1)/2
# Adjust to ensure non-zero counts for type 1 d' point estimate
adj_f <- 1/((nratings)*2)
nR_S1_adj = nR_S1 + adj_f
nR_S2_adj = nR_S2 + adj_f
ratingHR <- matrix()
ratingFAR <- matrix()
for (c in 2:(nratings*2)) {
ratingHR[c-1] <- sum(nR_S2_adj[c:length(nR_S2_adj)]) / sum(nR_S2_adj)
ratingFAR[c-1] <- sum(nR_S1_adj[c:length(nR_S1_adj)]) / sum(nR_S1_adj)
}
t1_index <- nratings
d1 <<- qnorm(ratingHR[(t1_index)]) - qnorm(ratingFAR[(t1_index)])
c1 <<- -0.5 * (qnorm(ratingHR[(t1_index)]) + qnorm(ratingFAR[(t1_index)]))
counts <- t(nR_S1) %>%
cbind(t(nR_S2))
counts <- as.vector(counts)
# Data preparation for model
data <- list(
d1 = d1,
c1 = c1,
counts = counts,
nratings = nratings,
Tol = Tol
)
## Model using JAGS
# Create and update model
model <- jags.model(file = 'Bayes_metad_indiv_R.txt', data = data,
n.chains = 3, quiet=FALSE)
update(model, n.iter=1000)
# Sampling
output <- coda.samples(
model          = model,
variable.names = c("meta_d", "cS1", "cS2"),
n.iter         = 10000,
thin           = 1 )
#Sum
Value <- summary(output)
stat <- data.frame(mean = Value[["statistics"]][, "Mean"])
stat %<>%
rownames_to_column(var = "name")
# Rhat
Value <- gelman.diag(output, confidence = 0.95)
Rhat <- data.frame(conv = Value$psrf)
# HDI
HDI <- data.frame(HPDinterval(output, prob = 0.95))
HDI %<>%
rownames_to_column(var = "name")
# All values in the same dataframe
Fit <- stat %>%
cbind(lower = HDI$lower,upper = HDI$upper)
#Filter
Fit <- Fit[-c(1:12), ]
Fit$d <- data$d1
Fit$criterion <- data$c1
Fit$ratingHR <- mean(ratingHR)
Fit$ratingFAR <- mean(ratingFAR)
Fit$mratio <-Fit$mean/Fit$d
return(Fit)
}
#Making a final dataframe for all participant data to be stored within
Meta_Cog_data <- data.frame()
#To Subset for 1 participant
#We Make a list of SUBJs
SUBJ_list <- as.list(unique(data$SUBJ))
#To Subset for 1 condition
#We Make a list of Conditions
Condition_list <- as.list(unique(data$Cond))
#We set the Working Directory to folder which includes the R Script leveraged by the Meta-Cognitive Model
# https://github.com/metacoglab/HMeta-d/blob/master/R/Function_metad_indiv.R
setwd("/Users/sebastianscottengen/Google Drev/Hogwarts/5/Bachelor stuff/EmotionalMetaMemory/code/tasks")
#Go into Subjects
for (n_subj in SUBJ_list){
#Go into Conditions
for(n_cond in Condition_list){
#Filter for Subj and Condition
Individisual_Dataframe <- filter(data,SUBJ==n_subj)
Individisual_Dataframe <- filter(Individisual_Dataframe,Cond==n_cond)
#Format coloumns for numeric values: Left == 0 and Right == 1
Individisual_Dataframe$Expected <- ifelse(Individisual_Dataframe$Expected == "right",1,0)
Individisual_Dataframe$KeyPressed <- ifelse(Individisual_Dataframe$KeyPressed == "right",1,0)
#Using Trial 2 Count for 1 Participant in 1 condition
# Starting by making the Lists for the function inputs:
stimID =    as.list(Individisual_Dataframe$Expected)
response =  as.list(Individisual_Dataframe$KeyPressed)
rating =    as.list(Individisual_Dataframe$Confidence)
nRatings = 7
#Running The Trial 2 Count Function
newlist = trials2counts(stimID,response,rating,nRatings)
#Seperating output into vectors containing the total number of responses in
#each response category, conditional on presentation of S1 and S2.
nR_S1 <- unlist(newlist[1], recursive = TRUE, use.names = TRUE)
nR_S2 <- unlist(newlist[2], recursive = TRUE, use.names = TRUE)
# Estimate metacognitive sensibility for subject with the MetaCognition Model
Fit <- metad_indiv(nR_S1 = nR_S1, nR_S2 = nR_S2)
#Add Subject and condition
Fit$SUBJ <- n_subj
Fit$Cond <- n_cond
#Bind inside the final dataframe
Meta_Cog_data <- rbind(Meta_Cog_data, Fit)
#Repeat for all conditions and subjects
}}
#Look at the Final Output Dataframe for the MetaCognition Model
Meta_Cog_data
#Backup the Dataframe as to avoid overwriting
Backup_Final <- Meta_Cog_data
#Add variables for Arousal and Valence
Meta_Cog_data$Arousal <- ifelse(Meta_Cog_data$Cond == "A+V+" | Meta_Cog_data$Cond == "A+V-",1,0)
Meta_Cog_data$Valence <- ifelse(Meta_Cog_data$Cond == "A-V+" | Meta_Cog_data$Cond == "A-V-",1,0)
#Rename Coloumn of Meta D prime
colnames(Meta_Cog_data)[2] <- "meta_d"
#Remove First coloumn which is an obsolete ID Coloumn
Meta_Cog_data = Meta_Cog_data[,-1]
#Merge the Final Meta Cognition Data with the Summary Data (Summary_data)
Meta_Summary <- merge(Meta_Cog_data,Summary_data,by = c("SUBJ", "Cond"))
#Merge with the Demographic Data
#Make the Democrafic data have the same format for IDs
demographic_data$ID <- paste0("Subject_", demographic_data$ID,".txt")
#Rename ID coloumn to SUBJ
colnames(demographic_data)[4] <- "SUBJ"
#Merge
Meta_Summary_Demo <- merge(Meta_Summary,demographic_data, by = "SUBJ")
# We look at Type 1 and Type 2 Errors
#FAR (Type2)>95% & HR (Type 1)<5%
boxplot(Meta_Summary_Demo$ratingHR)
boxplot(Meta_Summary_Demo$ratingFAR)
#Participants with mean d' less than or equal to 0 will be excluded because this indicates that they are unable to do the task.
#Participants with mean meta-d' less than or equal to 0 will be excluded because m-ratio is uninterpretable in these cases.
min(Meta_Summary_Demo$meta_d)
min(Meta_Summary_Demo$d)
#No mean d' or mean meta d' falls below 0 - so no reason to exclude
#If m-ratio cannot be estimated, for example because there is no variability in confidence reports or in accuracy, then that participant will be excluded.
#all m-ratios could be calculated and no participants needs exclusion
#Finally, outliers in task performance will be detected by inspecting boxplots of reaction time, d’, and confidence across all subjects; subjects whose values for any of these variables on any condition are greater than 1.5 times the interquartile range will be excluded from the analysis
#Plotting For Confidence and Reaction Time
hist(Meta_Summary_Demo$Confidence.median)
hist(Meta_Summary_Demo$RT.median)
ggplot(Meta_Summary_Demo, aes(x = Cond, y = Confidence.median)) + geom_boxplot(outlier.colour = "red")
ggplot(Meta_Summary_Demo, aes(x = Cond, y = RT.median)) + geom_boxplot(outlier.colour = "red")
#No Outlier detected in RT or Confidence
#Now For D'
hist(Meta_Summary_Demo$d)
ggplot(Meta_Summary_Demo, aes(x = Cond, y = d, label=SUBJ)) + geom_boxplot(outlier.colour = "red") +geom_text(aes(label=SUBJ),hjust=0, vjust=0)
#Subject 11138 and 11124 seem to be outliers and should therefore be excluded
Meta_Summary_Demo <- filter(Meta_Summary_Demo,SUBJ!= "Subject_11138.txt" & SUBJ!= "Subject_11124.txt")
unique(Meta_Summary_Demo$SUBJ)
#A total of 29 participants
#Save to CSV
write.csv(Meta_Summary_Demo, file = "FinalWithOutHeart.csv")
write.csv(Backup_Final, file = "FinalWithOutHeartBackUp.csv")
#Read the CSV
setwd("/Users/sebastianscottengen/Google Drev/Hogwarts/5/Bachelor stuff/EmotionalMetaMemory/code/tasks")
Meta_Summary_Demo <- read.csv("FinalWithOutHeart.csv")
#Drop first coloumn as it was added for no reason
Meta_Summary_Demo <- subset(Meta_Summary_Demo, select = -c(X))
#Format for Jasp (From Wide to Long Format)
library(reshape2)
Jasp <- Meta_Summary_Demo
Jasp <- select(Jasp,meta_d,d,criterion,SUBJ,Cond,mratio,Confidence.mean,RT.median,Confidence_RT.median, Accuracy_in_percent, Handedness_R_1,Total_Accepted_Trials,Gender_M_1)
Jasp <- Jasp%>%
pivot_wider(names_from = c(Cond),names_sep = "_",values_from = c(meta_d,d,criterion,mratio,Confidence.mean,RT.median,Confidence_RT.median, Accuracy_in_percent, Handedness_R_1,Total_Accepted_Trials,Gender_M_1))
Final_Jasp_Dataframe <- Jasp
write.csv(Final_Jasp_Dataframe,file = "Final_Jasp_Dataframe.csv")
