#Format coloumns for numeric values: Left == 0 and Right == 1
Individisual_Dataframe$Expected <- ifelse(Individisual_Dataframe$Expected == "right",1,0)
Individisual_Dataframe$KeyPressed <- ifelse(Individisual_Dataframe$KeyPressed == "right",1,0)
#Using Trial 2 Count for 1 Participant in 1 conditio
stimID =    as.list(Individisual_Dataframe$Expected)
response =  as.list(Individisual_Dataframe$KeyPressed)
rating =    as.list(Individisual_Dataframe$Confidence)
nRatings = 7
newlist = trials2counts(stimID,response,rating,nRatings)
nR_S1 <- unlist(newlist[1], recursive = TRUE, use.names = TRUE)
nR_S2 <- unlist(newlist[2], recursive = TRUE, use.names = TRUE)
# Estimate metacognitive sensibility (meta d') for individual subject
#Using function from earlier block
output <- metad_indiv(nR_S1 = nR_S1, nR_S2 = nR_S2)
# Find Mean Meta D' values
Value <- summary(output)
stat <- data.frame(mean = Value[["statistics"]][, "Mean"])
stat %<>%
rownames_to_column(var = "name")
#Filter
stat <- stat[-c(1:12), ]
#Add Subject and condition
stat$SUBJ <- i
stat$Cond <- x
#Put inside the final dataframe
Final_data <- rbind(Final_data, stat)
#Repeat
}}
#Final_data
Final_data
Final_data$Arousal <- ifelse(Final_data$Cond == "A+V+" | Final_data$Cond == "A+V-",1,0)
Final_data$Valence <- ifelse(Final_data$Cond == "A-V+" | Final_data$Cond == "A-V-",1,0)
ggplot(Final_data,aes(x=Arousal, y=mean)) + histogram()
ggplot(Final_data,aes(x=Arousal, y=mean))
ggplot(Final_data,aes(x=Arousal, y=mean))+geom_histogram(binwidth = 0.03, fill = "blue", colour = "grey", alpha = 0.5)
ggplot(Final_data,aes(x=Arousal, y=mean))+geom_histogram( colour = "grey", alpha = 0.5)
ggplot(Final_data,aes(x=Arousal, y=mean))+geom_histogram()
ggplot(Final_data,aes(x=Arousal, y=mean))+geom_bar()
ggplot(Final_data,aes(x=Arousal, y=mean,col=SUBJ))+geom_bar()
ggplot(Final_data,aes(x=Arousal, y=mean,col=SUBJ))
View(Final_data)
ggplot(Final_data,aes(x=mean, y=arousal,col=SUBJ))
ggplot(Final_data,aes(x=mean, y=Arousal,col=SUBJ))
ggplot(Final_data,aes(x=mean,col=Arousal))+
ggplot(Final_data,aes(x=mean,col=Arousal))+geom_histogram(binwidth = 0.03, fill = "blue", colour = "grey", alpha = 0.5
ggplot(Final_data,aes(x=mean,col=Arousal))+geom_histogram(binwidth = 0.03, fill = "blue", colour = "grey", alpha = 0.5)
#Final_data
Final_data
Final_data$Arousal <- ifelse(Final_data$Cond == "A+V+" | Final_data$Cond == "A+V-",1,0)
Final_data$Valence <- ifelse(Final_data$Cond == "A-V+" | Final_data$Cond == "A-V-",1,0)
ggplot(Final_data,aes(x=mean,col=Arousal))+geom_histogram(binwidth = 0.03, fill = "blue", colour = "grey", alpha = 0.5)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, colour = Arousal, alpha = 0.5)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, colour = Fianl_data$Arousal, alpha = 0.5)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, colour = Final_data$Arousal, alpha = 0.5)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, colour = Final_data$Arousal, alpha = 0.5)
ggplot(Final_data,aes(x=mean,colour = Arousal))+geom_histogram(binwidth = 0.03, alpha = 0.5)
ggplot(Final_data,aes(x=mean)+geom_histogram(binwidth = 0.03, alpha = 0.5,aes(colour = Arousal)
ggplot(Final_data,aes(x=mean)+geom_histogram(binwidth = 0.03, alpha = 0.5,aes(colour = Arousal))
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5,aes(colour = Arousal))
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5))
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5) +facet_wrap(~Arousal and Valence)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5) +facet_wrap(~Arousal+Valence)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5) +facet_wrap(~Arousal*Valence)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5) +facet_wrap(Valence~Arousal)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5) +facet_wrap(~Arousal)+facet_wrap(~Valence)
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5) +facet_wrap(~Valence)
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean, col=Cond))+geom_histogram(binwidth = 0.03, alpha = 0.5)
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean, fill=Cond))+geom_histogram(binwidth = 0.03, alpha = 0.5)
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5)+facet(~Cond)
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5)+facet(~Cond)
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean))+geom_histogram(binwidth = 0.03, alpha = 0.5)+facet(~Final_Data$Cond)
#Save to CSV
write.csv(Final_data, file = "MetaD_Data.csv")
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean))+ geom_violin(position = position_nudge(x = .5, y = 0),adjust =0.5, trim = TRUE)
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean))+ geom_violin()E)
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean))+ geom_violin()
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean,y=Cond))+ geom_violin()
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(x=mean,y=Cond))+ geom_boxplot()
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(y=mean,x=Cond))+ geom_boxplot()
#Plots of Meta D' for Arousal and
ggplot(Final_data,aes(y=mean,x=Cond))+ geom_boxplot()+geom_point()
View(data)
View(file)
#We also wan't to exlude all trials with reactiontimes faster than 100 milliseconds (Including negative reactiontimes)
file <- filter(file, Confidence_RT >= 0.100 & RT >= 0.100)
#We also wan't to exlude all trials with reactiontimes faster than 100 milliseconds (Including negative reactiontimes)
file <- filter(file, Confidence_RT >= 0.100 | RT >= 0.100)
#Next, any trial with RTs greater than 3 standard deviations than the median RT value will be removed
sdt(data$RT)
#Next, any trial with RTs greater than 3 standard deviations than the median RT value will be removed
histogram(data$Confidence_RT)
histogram(data$RT)
histogram(data$RT)+mean(data$RT)
#Make a list of names in Directory
filenames = list.files(pattern = "*.txt") #list of filenames from WD
#Test List
filenames
#Make Empty Dataframe
data = data.frame()
for (i in filenames){ #loop over list of files
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- i
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
# How Many NAs per SUBJ
file$NA_Sum <- sum(is.na(file))
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#How many per category + Precentage per category
file$NA_Cat
file$NA_Cat_Pre
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Then Exclude NAs
file <- na.omit(file)
#We also wan't to exlude all trials with reactiontimes faster than 100 milliseconds (Including negative reactiontimes)
file <- filter(file, Confidence_RT >= 0.100 | RT >= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
#Checking for all 35 participants
unique(data$SUBJ)
for (i in filenames){ #loop over list of files
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- i
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
# How Many NAs per SUBJ
file$NA_Sum <- sum(is.na(file))
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#How many per category + Precentage per category
file$NA_Cat
file$NA_Cat_Pre
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Then Exclude NAs
file <- na.omit(file)
#We also wan't to exlude all trials with reactiontimes faster than 100 milliseconds (Including negative reactiontimes)
file <- filter(file, Confidence_RT >= 0.100 | RT >= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
for (i in filenames){ #loop over list of files
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- i
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
# How Many NAs per SUBJ
file$NA_Sum <- sum(is.na(file))
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#How many per category + Precentage per category
file$NA_Cat
file$NA_Cat_Pre
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Then Exclude NAs
file <- na.omit(file)
#We also wan't to exlude all trials with reactiontimes faster than 100 milliseconds (Including negative reactiontimes)
file <- filter(file, Confidence_RT <= 0.100 | RT <= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
for (i in filenames){ #loop over list of files
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- i
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
# How Many NAs per SUBJ
file$NA_Sum <- sum(is.na(file))
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#How many per category + Precentage per category
file$NA_Cat
file$NA_Cat_Pre
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Then Exclude NAs
file <- na.omit(file)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
setwd("/Users/sebastianscottengen/Google Drev/EmotionalMetaMemory/data/TaskData/SUBJ Data")
#Make a list of names in Directory
filenames = list.files(pattern = "*.txt") #list of filenames from WD
#Test List
filenames
#Make Empty Dataframe
data = data.frame()
for (i in filenames){ #loop over list of files
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- i
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
# How Many NAs per SUBJ
file$NA_Sum <- sum(is.na(file))
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#How many per category + Precentage per category
file$NA_Cat
file$NA_Cat_Pre
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Then Exclude NAs
file <- na.omit(file)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
#Checking for all 35 participants
unique(data$SUBJ)
setwd("/Users/sebastianscottengen/Google Drev/EmotionalMetaMemory/data/TaskData/SUBJ Data")
#Make a list of names in Directory
filenames = list.files(pattern = "*.txt") #list of filenames from WD
#Test List
filenames
#Make Empty Dataframe
data = data.frame()
for (i in filenames){ #loop over list of files
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- i
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
# How Many NAs per SUBJ
file$NA_Sum <- sum(is.na(file))
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#How many per category + Precentage per category
file$NA_Cat
file$NA_Cat_Pre
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Then Exclude NAs
file <- na.omit(file)
#We also wan't to exlude all trials with reactiontimes faster than 100 milliseconds (Including negative reactiontimes)
file <- filter(file, Confidence_RT >= 0.100 | RT >= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
#Checking for all 35 participants
unique(data$SUBJ)
#Next, any trial with RTs greater than 3 standard deviations than the median RT value will be removed
histogram(data$Confidence_RT)
histogram(data$RT)
View(data)
#Set negative reactiontimes to NA
file[RT < 0] <- NA
#Set negative reactiontimes to NA
file[file < 0] <- NA
View(file)
#Then Exclude NAs
file <- na.omit(file)
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Set negative reactiontimes to NA
file[file < 0] <- NA
View(file)
#And Negative Trials
file <- filter(file, Confidence_RT !< 0 | RT !< 0)
#And Negative Trials
file <- filter(file, Confidence_RT !< 0 | RT !< 0))
#And Negative Trials
file <- filter(file, Confidence_RT <! 0 | RT <! 0))
#And Negative Trials
file <- filter(file, Confidence_RT <! 0 | RT <! 0)
View(file)
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#And Negative Trials
file <- filter(file, Confidence_RT <! 0.0 | RT <! 0.0)
View(file)
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Next, any trial with RTs greater than 3 standard deviations than the median RT value will be removed
histogram(data$Confidence_RT)
setwd("/Users/sebastianscottengen/Google Drev/EmotionalMetaMemory/data/TaskData/SUBJ Data")
#Make a list of names in Directory
filenames = list.files(pattern = "*.txt") #list of filenames from WD
#Test List
filenames
#Make Empty Dataframe
data = data.frame()
for (i in filenames){ #loop over list of files
#import the current file
file = read.delim(i, header=TRUE,sep = ",")
#Add Subjetline
file$SUBJ <- i
#Make Variable For Conditions
file$Cond <- ifelse(file$Arousal == "High" & file$Valence == "High","A+V+", ifelse(file$Arousal == "High" & file$Valence == "Low", "A+V-", ifelse(file$Arousal == "Low" & file$Valence == "High","A-V+","A-V-")))
# How Many NAs per SUBJ
file$NA_Sum <- sum(is.na(file))
# How Many NAs per SUBJ in Percent
file$NA_Sum_Pre <- file$NA_Sum/600
#How many per category + Precentage per category
file$NA_Cat
file$NA_Cat_Pre
temp_file1 <- subset(file,Cond == "A+V-")
temp_file1$NA_Sum <- sum(is.na(temp_file1))
temp_file1$NA_Sum_Pre <- temp_file1$NA_Sum/150
temp_file2 <- subset(file,Cond == "A-V+")
temp_file2$NA_Sum <- sum(is.na(temp_file2))
temp_file2$NA_Sum_Pre <- temp_file2$NA_Sum/150
temp_file3 <- subset(file,Cond == "A+V+")
temp_file3$NA_Sum <- sum(is.na(temp_file3))
temp_file3$NA_Sum_Pre <- temp_file3$NA_Sum/150
temp_file4 <- subset(file,Cond == "A-V-")
temp_file4$NA_Sum <- sum(is.na(temp_file4))
temp_file4$NA_Sum_Pre <- temp_file4$NA_Sum/150
file$NA_Cat <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum,temp_file4$NA_Sum)))
file$NA_Cat_Pre <- ifelse(file$Cond == "A+V-",temp_file1$NA_Sum_Pre, ifelse(file$Cond == "A-V+", temp_file2$NA_Sum_Pre, ifelse(file$Cond == "A+V+",temp_file3$NA_Sum_Pre,temp_file4$NA_Sum_Pre)))
#Then Exclude NAs
file <- na.omit(file)
#We also wan't to exlude all trials with reactiontimes faster than 100 milliseconds
file <- filter(file, Confidence_RT >= 0.100)
file <- filter(file, RT >= 0.100)
#Something happend to the accuracy-scores of SUBJ 11123 - So we'll try to force them into numerics
#Make Accuracy Scores Numeric
file$Accuracy <- (ifelse(file$Accuracy == "True" | file$Accuracy == "1.0" | file$Accuracy == "1", "1", "0"))
#Bind To Complete Dataframe
data = rbind(data, file[,])
}
#Checking for all 35 participants
unique(data$SUBJ)
#Checking for Participants with conditions with fewer than 50 trials
subset <- data[which(data[,21]>=0.66),]
#The Low Arousal and Low Valence group (A-V-) for Subject 47284 has below 50 "good" trials and must therefore be excluded
data <- filter(data,SUBJ!="Subject_47542.txt")
unique(data$SUBJ)
#Next, any trial with RTs greater than 3 standard deviations than the median RT value will be removed
histogram(data$Confidence_RT)
histogram(data$RT)
# Mean values
Value <- summary(output)
stat <- data.frame(mean = Value[["statistics"]][, "Mean"])
stat %<>%
rownames_to_column(var = "name")
# Rhat
Value <- gelman.diag(output, confidence = 0.95)
Rhat <- data.frame(conv = Value$psrf)
# HDI
HDI <- data.frame(HPDinterval(output, prob = 0.95))
HDI %<>%
rownames_to_column(var = "name")
# All values in the same dataframe
Fit <- stat %>%
cbind(lower = HDI$lower,
upper = HDI$upper)
View(Fit)
#Making a final dataframe for all participant data to be stored within
Final_data <- data.frame()
#Subset for 1 participant
#Make list of SUBJs
SUBJ_list <- as.list(unique(data$SUBJ))
Condition_list <- as.list(unique(data$Cond))
#Go into Subjects
for (i in SUBJ_list){
#Go into Conditions
for(x in Condition_list){
Individisual_Dataframe <- filter(data,SUBJ==i)
Individisual_Dataframe <- filter(Individisual_Dataframe,Cond==x)
#Format coloumns for numeric values: Left == 0 and Right == 1
Individisual_Dataframe$Expected <- ifelse(Individisual_Dataframe$Expected == "right",1,0)
Individisual_Dataframe$KeyPressed <- ifelse(Individisual_Dataframe$KeyPressed == "right",1,0)
#Using Trial 2 Count for 1 Participant in 1 conditio
stimID =    as.list(Individisual_Dataframe$Expected)
response =  as.list(Individisual_Dataframe$KeyPressed)
rating =    as.list(Individisual_Dataframe$Confidence)
nRatings = 7
newlist = trials2counts(stimID,response,rating,nRatings)
nR_S1 <- unlist(newlist[1], recursive = TRUE, use.names = TRUE)
nR_S2 <- unlist(newlist[2], recursive = TRUE, use.names = TRUE)
# Estimate metacognitive sensibility (meta d') for individual subject
#Using function from earlier block
output <- metad_indiv(nR_S1 = nR_S1, nR_S2 = nR_S2)
# Find Mean Meta D' values
Value <- summary(output)
stat <- data.frame(mean = Value[["statistics"]][, "Mean"])
stat %<>%
rownames_to_column(var = "name")
# Rhat
Value <- gelman.diag(output, confidence = 0.95)
Rhat <- data.frame(conv = Value$psrf)
# HDI
HDI <- data.frame(HPDinterval(output, prob = 0.95))
HDI %<>%
rownames_to_column(var = "name")
# All values in the same dataframe
Fit <- stat %>%
cbind(lower = HDI$lower,upper = HDI$upper)
#Filter
Fit <- Fit[-c(1:12), ]
#Add Subject and condition
Fit$SUBJ <- i
Fit$Cond <- x
#Put inside the final dataframe
Final_data <- rbind(Final_data, Fit)
#Repeat
}}
